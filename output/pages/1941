b'Xinhua Zhang'
b'Home'
b'\nPapers\nCode\nResearch\nTeaching\n\nCV (pdf)\nLinks\n'
b'Papers'
b'Code'
b'Research'
b'Teaching'
b'CV (pdf)'
b'Links'
b'\n'
b'Xinhua Zhang '
b'Assistant Professor\nDepartment of Computer Science '
b'Department of Computer Science'
b'\nUniversity of Illinois at Chicago\n\xc2\xa0'
b'\nUniversity of Illinois at Chicago'
b'\nNorth End, Level 3, Richard Daley Library'
b'\nDepartment of Computer Science'
b'\nUniversity of Illinois at Chicago'
b'\nChicago, IL, 60607-7053\n\xc2\xa0'
b'\nTel: \xc2\xa0\xc2\xa0\xc2\xa0312-413-2416 (O)'
b'\nEmail: \n<!-- \n// protected email script by Joe Maller\n// JavaScripts available at http://www.joemaller.com\n// this script is free to use and distribute\n// but please credit me and/or link to my site\n\nemailE=(\'zhangx@\' + \'uic.edu\')\ndocument.write(\'<A href="mailto:\' + emailE + \'">\' + emailE + \'</a>\')\n\n //-->\n\n\nEmail address protected by JavaScript.\n    Please enable JavaScript to contact me.\n\n'
b'\xc2\xa0\xc2\xa0'
b"\xc2\xa0\n Introduction to Machine Learning for Fall 2018: [Syllabus]\n\xc2\xa0\xc2\xa0\xc2\xa0\n Announcment for CS 412: please refer to Piazza.  Seats are allocated on a first come first served basis.\n\n\n\n\t\xc2\xa0\n\n\nResearch Interests\nMy current research in machine learning focuses on convex models for learning predictive representation. Most existing machine learning methods infer representation from data in a way that is independent of its subsequent use, e.g. learning a predictive model. This is suboptimal. My research goal is to jointly infer latent representation and learn predictors for massive datasets by combining them into a single convex optimization problem. Convexity allows jointly optimal solutions to be found for these two tasks, and scale up efficiently to large application problems. To achieve this goal, my key strategies are: 1) find appropriate convex relaxations that retain the structure of the data, e.g. semi-definite relaxations; and 2) design efficient algorithms for optimization such as low-rank approximation.\n\nI work on applications in pattern recognition, document analysis, image \nprocessing, and any prediction problem that is useful in life.\nBiography\n\nPrior to joining UIC in Nov 2015, I was a Senior Researcher at the \nMachine Learning Research Group \nof National ICT Australia (NICTA, now Data61). \nFrom April 2010 to September 2012, I was a post-doc working with Prof\nDale Schuurmans at the\nDepartment of Computing Science,\nUniversity of Alberta.\xc2\xa0 From March 2006 \nto October 2009,\nI was a NICTA-endorsed PhD student of the\xc2\xa0Research School of Computer Science, Australian National \nUniversity (ANU), working with\xc2\xa0Prof SVN Vishwanathan and Prof Alex Smola.\xc2\xa0 I visited\nProf SVN Vishwanathan at the\nDepartment of Statistics at\nPurdue University from February 2009 to \nMarch 2010.\xc2\xa0 From January 2004 to March 2006, I \npursued my Master's degree (by research) under the supervision of Prof Wee Sun Lee at the\nDepartment of Computer Science,\nNational University of Singapore (NUS). I \nreceived my B.E. from the\nDepartment of \nComputer Science and Engineering at\nShanghai Jiao Tong University in \nJuly 2003.  My hometown is Shanghai.\nFind Me\n\nTalks on Videolectures\n\n\n"
b'[Syllabus]'
b'\xc2\xa0\xc2\xa0'
b"\xc2\xa0\n Announcment for CS 412: please refer to Piazza.  Seats are allocated on a first come first served basis.\n\n\n\n\t\xc2\xa0\n\n\nResearch Interests\nMy current research in machine learning focuses on convex models for learning predictive representation. Most existing machine learning methods infer representation from data in a way that is independent of its subsequent use, e.g. learning a predictive model. This is suboptimal. My research goal is to jointly infer latent representation and learn predictors for massive datasets by combining them into a single convex optimization problem. Convexity allows jointly optimal solutions to be found for these two tasks, and scale up efficiently to large application problems. To achieve this goal, my key strategies are: 1) find appropriate convex relaxations that retain the structure of the data, e.g. semi-definite relaxations; and 2) design efficient algorithms for optimization such as low-rank approximation.\n\nI work on applications in pattern recognition, document analysis, image \nprocessing, and any prediction problem that is useful in life.\nBiography\n\nPrior to joining UIC in Nov 2015, I was a Senior Researcher at the \nMachine Learning Research Group \nof National ICT Australia (NICTA, now Data61). \nFrom April 2010 to September 2012, I was a post-doc working with Prof\nDale Schuurmans at the\nDepartment of Computing Science,\nUniversity of Alberta.\xc2\xa0 From March 2006 \nto October 2009,\nI was a NICTA-endorsed PhD student of the\xc2\xa0Research School of Computer Science, Australian National \nUniversity (ANU), working with\xc2\xa0Prof SVN Vishwanathan and Prof Alex Smola.\xc2\xa0 I visited\nProf SVN Vishwanathan at the\nDepartment of Statistics at\nPurdue University from February 2009 to \nMarch 2010.\xc2\xa0 From January 2004 to March 2006, I \npursued my Master's degree (by research) under the supervision of Prof Wee Sun Lee at the\nDepartment of Computer Science,\nNational University of Singapore (NUS). I \nreceived my B.E. from the\nDepartment of \nComputer Science and Engineering at\nShanghai Jiao Tong University in \nJuly 2003.  My hometown is Shanghai.\nFind Me\n\nTalks on Videolectures\n\n\n"
b'Piazza'
b'\n\t\xc2\xa0\n'
b'Research Interests'
b'My current research in machine learning focuses on convex models for learning predictive representation. Most existing machine learning methods infer representation from data in a way that is independent of its subsequent use, e.g. learning a predictive model. This is suboptimal. My research goal is to jointly infer latent representation and learn predictors for massive datasets by combining them into a single convex optimization problem. Convexity allows jointly optimal solutions to be found for these two tasks, and scale up efficiently to large application problems. To achieve this goal, my key strategies are: 1) find appropriate convex relaxations that retain the structure of the data, e.g. semi-definite relaxations; and 2) design efficient algorithms for optimization such as low-rank approximation.\n'
b'I work on applications in pattern recognition, document analysis, image \nprocessing, and any prediction problem that is useful in life.'
b'Biography'
b"\nPrior to joining UIC in Nov 2015, I was a Senior Researcher at the \nMachine Learning Research Group \nof National ICT Australia (NICTA, now Data61). \nFrom April 2010 to September 2012, I was a post-doc working with Prof\nDale Schuurmans at the\nDepartment of Computing Science,\nUniversity of Alberta.\xc2\xa0 From March 2006 \nto October 2009,\nI was a NICTA-endorsed PhD student of the\xc2\xa0Research School of Computer Science, Australian National \nUniversity (ANU), working with\xc2\xa0Prof SVN Vishwanathan and Prof Alex Smola.\xc2\xa0 I visited\nProf SVN Vishwanathan at the\nDepartment of Statistics at\nPurdue University from February 2009 to \nMarch 2010.\xc2\xa0 From January 2004 to March 2006, I \npursued my Master's degree (by research) under the supervision of Prof Wee Sun Lee at the\nDepartment of Computer Science,\nNational University of Singapore (NUS). I \nreceived my B.E. from the\nDepartment of \nComputer Science and Engineering at\nShanghai Jiao Tong University in \nJuly 2003.  My hometown is Shanghai."
b'Machine Learning Research Group'
b'National ICT Australia (NICTA, now Data61)'
b'Dale Schuurmans'
b'Department of Computing Science'
b'University of Alberta'
b'NICTA'
b'Research School of Computer Science'
b'Australian National \nUniversity'
b'Prof SVN Vishwanathan'
b'Prof Alex Smola'
b'Prof SVN Vishwanathan'
b'Department of Statistics'
b'Purdue University'
b'Prof Wee Sun Lee'
b'Department of Computer Science'
b'National University of Singapore'
b'Department of \nComputer Science and Engineering'
b'Shanghai Jiao Tong University'
b'Find Me'
b'Talks on Videolectures'
b'Alex Smola'
b''
